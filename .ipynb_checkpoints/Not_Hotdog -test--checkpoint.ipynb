{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tf18/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage import exposure\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Image Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImage(img, angle):\n",
    "    (rows, cols, ch) = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (cols,rows))\n",
    "    \n",
    "    \n",
    "def loadBlurImg(path, imgSize):\n",
    "    img = cv2.imread(path)\n",
    "    angle = np.random.randint(0, 360)\n",
    "    img = rotateImage(img, angle)\n",
    "    img = cv2.blur(img,(5,5))\n",
    "    img = cv2.resize(img, imgSize)\n",
    "    return img\n",
    "\n",
    "def loadImgClass(classPath, classLable, classSize, imgSize):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for path in classPath:\n",
    "        img = loadBlurImg(path, imgSize)        \n",
    "        x.append(img)\n",
    "        y.append(classLable)\n",
    "        \n",
    "    while len(x) < classSize:\n",
    "        randIdx = np.random.randint(0, len(classPath))\n",
    "        img = loadBlurImg(classPath[randIdx], imgSize)\n",
    "        x.append(img)\n",
    "        y.append(classLable)\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "def loadData(img_size, classSize):\n",
    "    hotdogs = glob.glob('./data/hot_dog/**/*.jpg', recursive=True)\n",
    "    notHotdogs = glob.glob('./data/not_hot_dog/**/*.jpg', recursive=True)\n",
    "    \n",
    "    \n",
    "    imgSize = (img_size, img_size)\n",
    "    xHotdog, yHotdog = loadImgClass(hotdogs, 0, classSize, imgSize)\n",
    "    xNotHotdog, yNotHotdog = loadImgClass(notHotdogs, 1, classSize, imgSize)\n",
    "    print(\"There are\", len(xHotdog), \"hotdog images\")\n",
    "    print(\"There are\", len(xNotHotdog), \"not hotdog images\")\n",
    "    \n",
    "    X = np.array(xHotdog + xNotHotdog)\n",
    "    y = np.array(yHotdog + yNotHotdog)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGray(images):\n",
    "    # rgb2gray converts RGB values to grayscale values by forming a weighted sum of the R, G, and B components:\n",
    "    # 0.2989 * R + 0.5870 * G + 0.1140 * B \n",
    "    # source: https://www.mathworks.com/help/matlab/ref/rgb2gray.html\n",
    "    \n",
    "    images = 0.2989*images[:,:,:,0] + 0.5870*images[:,:,:,1] + 0.1140*images[:,:,:,2]\n",
    "    return images\n",
    "\n",
    "def normalizeImages(images):\n",
    "    # use Histogram equalization to get a better range\n",
    "    # source http://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.equalize_hist\n",
    "    images = (images / 255.).astype(np.float32)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        images[i] = exposure.equalize_hist(images[i])\n",
    "    \n",
    "    images = images.reshape(images.shape + (1,)) \n",
    "    return images\n",
    "\n",
    "def preprocessData(images):\n",
    "    grayImages = toGray(images)\n",
    "    return normalizeImages(grayImages)\n",
    "\n",
    "def normalizeImages2(images):\n",
    "    for i in range(images.shape[0]):\n",
    "        cv2.normalize(images[i],images[i], alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    # if convert to gray scale use this after\n",
    "    print(\"images has shape before\", images.shape)\n",
    "    #images = images.reshape(images.shape + (1,)) \n",
    "    #print(\"images has shape after\", images.shape)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5000 hotdog images\n",
      "There are 5000 not hotdog images\n"
     ]
    }
   ],
   "source": [
    "size = 128\n",
    "classSize = 5000\n",
    "\n",
    "scaled_X, y = loadData(size, classSize)\n",
    "scaled_X = preprocessData(scaled_X)\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes = 2\n",
      "train shape X (8000, 128, 128, 1)\n",
      "train shape y (8000, 2)\n"
     ]
    }
   ],
   "source": [
    "rand_state = np.random.randint(0, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print(\"Number of classes =\", n_classes)\n",
    "print(\"train shape X\", X_train.shape)\n",
    "print(\"train shape y\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def karasModel(inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(16, (5, 5), input_shape=inputShape, activation=\"elu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(32, (3, 3), border_mode=\"same\", activation=\"elu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(64, (3, 3), border_mode=\"same\", activation=\"elu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    model.add(Dense(1024, activation=\"elu\"))\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tf18/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (2, 2), activation=\"elu\", padding=\"same\")`\n",
      "/home/ubuntu/anaconda3/envs/tf18/lib/python3.5/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 2), activation=\"elu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 7.9638 - acc: 0.5034 - val_loss: 8.2041 - val_acc: 0.4910\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 8.0228 - acc: 0.5022 - val_loss: 8.2041 - val_acc: 0.4910\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 8.0228 - acc: 0.5022 - val_loss: 8.2041 - val_acc: 0.4910\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 8.0228 - acc: 0.5022 - val_loss: 8.2041 - val_acc: 0.4910\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 8.0228 - acc: 0.5022 - val_loss: 8.2041 - val_acc: 0.4910\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 8.0228 - acc: 0.5022 - val_loss: 8.2041 - val_acc: 0.4910\n",
      "Epoch 7/10\n",
      "3488/8000 [============>.................] - ETA: 5s - loss: 8.0175 - acc: 0.5026"
     ]
    }
   ],
   "source": [
    "inputShape = (size, size, 1)\n",
    "model = karasModel(inputShape)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf18]",
   "language": "python",
   "name": "conda-env-tf18-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
